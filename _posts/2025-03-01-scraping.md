---
title: "Web Scraping"
date: 2025-03-01
categories: ["Tutorial", "Data Science"]
tags: ["Web Scraping", "Python", "BeautifulSoup", "Requests"]

---


# ğŸ“Œ Pengenalan Web Scraping

## Apa Itu Web Scraping?

Web scraping adalah teknik untuk mengumpulkan data secara otomatis dari sebuah halaman web. Teknik ini digunakan untuk mengambil informasi yang tersedia di internet dan menyusunnya dalam format yang lebih mudah diproses, seperti CSV atau database.

Dengan menggunakan Python, kita bisa memanfaatkan pustaka seperti **requests** untuk mengambil data dari web dan **BeautifulSoup** untuk memproses dan mengekstrak data dari HTML.

---

## ğŸ›  Instalasi

Sebelum memulai scraping, pastikan pustaka berikut telah terinstal:

```sh
pip install requests beautifulsoup4
```

Pustaka yang digunakan:

- `requests`: Untuk mengambil data dari halaman web.
- `BeautifulSoup`: Untuk memproses dan mengekstrak data dari HTML.
- `csv`: Untuk menyimpan hasil scraping dalam format CSV.

---

## ğŸš€ Implementasi Web Scraping

Berikut adalah contoh implementasi scraping menggunakan Python untuk mengambil informasi negara dari situs **scrapethissite.com**.

### ğŸ“œ Contoh Kode

```python
import requests
from bs4 import BeautifulSoup
import csv

# Step 1: Request halaman web
url = "https://www.scrapethissite.com/pages/simple/"
headers = {"User-Agent": "Mozilla/5.0"}
response = requests.get(url, headers=headers)

# Step 2: Parsing HTML
soup = BeautifulSoup(response.text, "html.parser")

# Step 3: Menemukan semua elemen negara
countries = soup.find_all("div", class_="col-md-4 country")

# Step 4: Menyiapkan list untuk menyimpan data sebelum ditulis ke CSV
data_negara = []

# Step 5: Loop untuk mengambil name, capital, population, dan area
for country in countries:
    name = country.find("h3", class_="country-name").text.strip()  # Nama negara
    capital = country.find("span", class_="country-capital").text.strip()  # Ibukota
    population = country.find("span", class_="country-population").text.strip()  # Populasi
    area = country.find("span", class_="country-area").text.strip()  # Luas wilayah

    print(name)
    print(capital)
    print(population)
    print(area)

    # Simpan ke list
    data_negara.append([name, capital, population, area])

# Step 6: Menyimpan data ke CSV
with open("negara.csv", "w", newline="", encoding="utf-8") as file:
    writer = csv.writer(file)
    writer.writerow(["Name", "Capital", "Population", "Area"])
    writer.writerows(data_negara)

print("Data berhasil disimpan ke negara.csv! ğŸ‰")
```

---

## ğŸ” Penjelasan Kode

1ï¸âƒ£ **Mengirim Request ke Website**

- `requests.get(url, headers=headers)`: Mengunduh halaman web dengan user-agent agar tidak terdeteksi sebagai bot.

2ï¸âƒ£ **Parsing HTML**

- `BeautifulSoup(response.text, "html.parser")`: Mengubah teks HTML menjadi objek yang bisa diproses.

3ï¸âƒ£ **Menemukan Elemen Data**

- `soup.find_all("div", class_="col-md-4 country")`: Mencari semua elemen yang menyimpan informasi negara.

4ï¸âƒ£ **Mengekstrak Data**

- `find("h3", class_="country-name").text.strip()`: Mengambil nama negara.
- `find("span", class_="country-capital").text.strip()`: Mengambil ibu kota.
- `find("span", class_="country-population").text.strip()`: Mengambil populasi.
- `find("span", class_="country-area").text.strip()`: Mengambil luas wilayah.

5ï¸âƒ£ **Menyimpan Data ke CSV**

- `csv.writer(file).writerow(["Name", "Capital", "Population", "Area"])`: Menulis header file CSV.
- `writer.writerows(data_negara)`: Menulis data yang telah dikumpulkan.

---

## ğŸ“Œ Kesimpulan

Web scraping adalah teknik yang kuat untuk mengumpulkan data dari web. Dengan menggunakan **requests** dan **BeautifulSoup**, kita bisa mengambil dan memproses informasi dari berbagai situs web secara otomatis. Pastikan untuk selalu mematuhi aturan penggunaan website yang diakses!

ğŸ’¡ **Tips:**

- Selalu gunakan **User-Agent** agar tidak mudah terdeteksi sebagai bot.
- Periksa **robots.txt** dari situs web untuk memastikan scraping diperbolehkan.
- Gunakan **delay** atau **proxy** jika scraping dalam jumlah besar.

ğŸ”— **Referensi Tambahan:**

- [BeautifulSoup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [Requests Documentation](https://docs.python-requests.org/en/latest/)

ğŸš€ **Bagikan proyek ini di GitHub.io agar lebih profesional!**

